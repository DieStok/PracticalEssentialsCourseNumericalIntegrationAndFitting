---
title: "Basic Parameter fitting Ram et al. Paper"
output:
  html_document:
    df_print: paged
---

```{r, include= FALSE}
#loading required packages and sourcing Grind
if(!require(pacman)) {
install.packages("pacman"); require(pacman)}
p_load(tidyverse, rootSolve, deSolve, FME)
source("grind.R")
source("../HelperFunctionsAnswerFile.R")

```
#Question 2
Before we start to fit, let us have a look at the data

```{r}
# The 3 experiments are indexed by their date:
exptA <- "2015-11-18"  #Experiment A
exptB <- "2015-12-14"  #Experiment B
exptC <- "2016-01-06"  #Experiment C

#Let us read in data of Figure 3 for experiment A
fig3RA <- read.csv(paste("Fig3/",exptA,"_R.csv",sep="")) # Red strain
fig3GA <- read.csv(paste("Fig3/",exptA,"_G.csv",sep="")) # Green strain
plot(fig3RA$Time, fig3RA$OD, ylim=c(0,0.8),col="red",pch=".",xlab="Time (hr)",ylab="OD", main = "Figure 3 A1 (red) and A2 (green)")
points(fig3GA$Time, fig3GA$OD, ylim=c(0,0.8),col="green",pch=".")

fig4 <- read.csv(paste("Fig4/",exptA,"_RG.csv",sep=""))
plot(fig4$Time, fig4$OD, ylim=c(0,0.8), col="blue", pch=".", xlab="Time (hr)", ylab="Total OD", main = "Figure 4 A")

fig5 <- read.csv(paste("Fig5/flow_df_",exptA,".csv",sep=""))
fig5G <- fig5[fig5$Strain=="Green",]
fig5R <- fig5[fig5$Strain=="Red",]
plot(fig5G$time, fig5G$freq_mean, ylim=c(0,1), col="green",xlab="Time (hr)", ylab="Frequency", main =  "Figure 5 A")
points(fig5R$time, fig5R$freq_mean, col="red")

#Q2A answer:
#Note that due to the 30-32 replicates, in Fig 3 and Fig 4 you see for each timepoint a line of points with each point corresponding to a single measurement. Apparently in Fig5 mean values are used instead.

```


Now to fit we first need to define the model

```{r}

model <- function(t, state, parms) {
  with(as.list(c(state,parms)), {
    a <- q0/(q0+exp(-m*t))
    dN <- r*a*N*(1-(N/K)^v)
    return(list(dN))  
  }) 
}

s <- c(N=0.124)
p <- c(K=0.6,r=0.4,m=2,q0=0.005,v=2)
```


To fit, we need to do two more things:
1. Tell Grind which parameters we would like to fit to the data. All other parameters will be kept constant, at a previously defined value.
2. Tell Grind what the lower and/or upper bounds are for certain parameters. E.g. we don't want negative growth speeds, so r would need a lower bound of 0. Similarly, Ram et al., specifiy that v should be equal or larger than 1, so that would require a lower bound of 1. If nothing is specified the parameter fit can take on any value.

```{r}
#N + all the parameters are free to be fitted. 
free <- c("N",names(p))
#for the lower bound, we bound everything at 0, and v at 1.
#so you first use the length of the vector free to first set lower bound for all parameters to zero
#next for parameter v specifically you set the lower bound to 1
lower <- rep(0, length(free)); lower[match("v",free)] <- 1; lower  # set lower bounds


#to fit, Grind wants a data frame with time and the variables it needs to fit. Note how we rename OD to N to be consistent.
data3RA <- as.data.frame(cbind(fig3RA$Time,fig3RA$OD)); names(data3RA) <- c("time","N")

#now we fit the parameters. fun = log tells the fitting that we want to fit the log of the data, not the actual data. The other parameters are self-explanatory. Note that we also start from some initial guess for the parameter values and try to improve the fit from there. For now, we'll just use the parameters from above.
fit3RAlog  <- fit(data3RA, state = s, odes = model, parms = p,
               free=free, fun=log, lower=lower, pch=".",
               legend=FALSE, tstep=0.1, main="Fig 3 a red monoculture (fun=log)",
               ymin = 0, ymax = 1
               )
#in this fit, you can get at the fitted parameters using $par
print(fit3RAlog$par)


#Q2B answer: not doing the log
fit3RA     <- fit(data3RA, state = s, odes = model, parms = p,
               free=free, lower=lower, pch=".",
               legend=FALSE, tstep=0.1, main="Fig 3 a red monoculture",
               ymin = 0, ymax = 1
               )
#In the article the data is not log transformed
#You see that in this particular case taking a log-transform does not impact the quality of the fit much. Still one can imagine that a log-transform is important to weigh a difference of 0.1 relative to a mean of 1 equally heavily as a difference of 10 to a mean of 100. Also, one would want many small differences to count equally as a single large difference, for this a log transform also helps.
```

Now look at fitting statistics
```{r}
#Q2C&D answer
summary(fit3RAlog)

#Q2C
#The estimated value for N is the estimate for its initial value at time zero
#The standard deviation implies that not a single "fitting run" was done but
#a whole series for which a mean and standard deviation could be computed
#the t value is defined as the estimated value/standard deviation so a large
#value means little variation relative to the mean obtained value 
#the t value is subsequently used in a T table (student t test) to determine
#the likelihood of this estimate not being correct

#Q2D
#If parameters are strongly correlated it means that if the fitting procedure
#obtains a higher value for one it does so too for the other, whereas in case of
#anticorrelation a higher fitted value for one corresponds to a lower fitted value
#for the other. The first may occur for e.g birth and death rates, same population
#numbers may arise if birth and death are both low or both high. The latter may
#occur for birth and immigration rates, same population numbers may occur if one
#is high and the other low. The fact that parameters (anti)correlate means that
#there is insufficient data to decide which of the possible pairs of values is 
#the right one, so the model is underdetermined and one should consider collapsing
#these parameters into a single net one.
```

```{r}
#Q2E
#here you can write code to do the same as above but now for the red strain in Fig 3B
#make sure to look at both parameter values and fit statistics

#Q2E answer
#simply do the same as before for figure 3A, red strain:
fig3RB <- read.csv(paste("Fig3/",exptB,"_R.csv",sep="")) # Red strain
data3RB <- as.data.frame(cbind(fig3RB$Time,fig3RB$OD)); names(data3RB) <- c("time","N")
fit3RBlog  <- fit(data3RB, state = s, odes = model, parms = p,
               free=free, fun=log, lower=lower, pch=".",
               legend=FALSE, tstep=0.1, main="Fig 3 b red monoculture (fun=log)",
               ymin = 0, ymax = 1
               )
print(fit3RBlog$par)
summary(fit3RBlog)
#you see that a very large value of q0 is obtained, meaning that this delay fraction
#is approximately equal to 1 from time is zero onwards, obliterating this startup phase
#function's impact. 
#however from the fit statistics summary we also see that there are issues with this fit:
#covariances could not be estimated. So while at first sight it seems that the fitting itself can 
#figure out there is no delay phase, these issues suggest that if you have information that certain 
#processes and hence parameters are not relevant you should use that information and not try to fit 
#q0 and m here
```


The below loads in all the data from Fig3 of the Ram paper(both their data and their fits). This data is in a list. You can look at sections of this list using $ or [[]]. This comes in handy when wanting to fit the model to multiple data sets at once. As for the plots of the standard fits, note that unfortunately Grind's standard time plot uses a specific colour palette, one for each ODE to plot, and since we fit green and red separately it is not easily possible to make the colours green for the green bacteria.

```{r}
dataAndFitsFigureThree = readInDataFigureThreeRamPaper()

#you can access the data using either $ or [[]]:
head(dataAndFitsFigureThree$DataexptAFig3G)
head(dataAndFitsFigureThree[["DataexptAFig3R"]])

```
```{r}
#Question 3

#Q3A Given that the strains are the same but growing under different conditions intrinsic strain properties such as r, K and v are expected to be similar, whereas conditions dependent parameters such as q0 and m may likely differ
```

#Q3B
To do this, we need to tell the fit function of
-What parameters to fit for all data together (free parameters)
-What parameters to fit separately per dataset (different parameters).
-Which data sets to use for fitting

```{r}
#set up initial state, and initial guess for parameter values
s <- c(N=0.124)
p <- c(K=0.6,r=0.4,m=2,q0=0.005,v=2)
#all parameters are fitted
free <- c("N",names(p)) 
#define the parameters for which different values should be obtained from different data sets, for all other parameters a single fit value is obtained from the combined data sets
differ <- c("q0", "m")
#define the list of data sets to be fitted to
l <- list(dataAndFitsFigureThree$DataexptAFig3R, dataAndFitsFigureThree$DataexptBFig3R)
```
As before we need to set the lower bound of v to 1. But now, we are fitting 2*the parameters that differ per dataset, + all those that don't for all data together. So we need some code to make sure that we set the right parameter to have a lower bound of 1. To do that, we use the following:

```{r}
#the total number of parameters to fit = 2 * those in differ (as these need to be fitted twice, once
#for each data set) + all remaining parameters in free that should be fitted combined for the two datasets
totfree <- c(free[!(free %in% differ)], differ, differ)
npar <- length(totfree)
cat("Number of free parameters",npar)

#Now set all instances of v in the total number of parameters to have a lower bound of1, and all the other lower bounds to 0
lower <- rep(0,npar); lower[which(totfree == "v")] <- 1; lower  # set lower bounds
```
Now do the combined fitting

```{r}
fitq0mdiffer <- fit(data=l, free=free, differ=differ, fun=log, odes = model, state = s, parms = p, lower=lower, pch=".",legend=FALSE, tstep=0.1,  main="Red from A and B, q0 andd m differing", add=TRUE, ymin = 0, ymax = 1)
summary(fitq0mdiffer)
fitq0mdiffer$ssr

#Q3B
#In principle what we do here is better as we use more data (two data sets) to determine the same 
#parameters (N,K,r,v), rather than determining these parameters twice from two different data sets

#Q3C
#Still, we do have the issue we encountered earlier for the second data set, in which there is no lag #phase, that still trying to fit q0 and m to this data gives a high value of q0 and problems with
#co-variances indicating this is not such a good idea.
#So ideally, N,K,r and v should be fitted from both data sets, and q0 and m only for the first,
#while not fitting these for the second data set.
```

# Question 4

```{r}
#Q4A: define the 2D model here

#Q4A answer
model2 <- function(t, state, parms) {
  with(as.list(c(state,parms)), {
    a1 <- q01/(q01+exp(-m1*t)); a2 <- q02/(q02+exp(-m2*t))
    dN1 <- r1*a1*N1*(1-(N1/K1)^v1-c2*(N2^v2)/(K1^v1))
    dN2 <- r2*a2*N2*(1-(N2/K2)^v2-c1*(N1^v1)/(K2^v2))
    return(list(c(dN1,dN2)))  
  }) 
}
```
Now let us read in the parameters as Ram et al. fitted them to figure 3A for the red and green strain
and let us construct a parameter vector for the 2D model from this

```{r}
# Take the parameters from the single fits (we now use the fitted values obtained in the paper). 
# Parameters are renamed, appending indices 1 and 2, respectively for the red (R) and green (G)
# strains.
pR        <- dataAndFitsFigureThree$FitexptAFig3R$par[2:length(dataAndFitsFigureThree$FitexptAFig3R$par)]
names(pR) <- paste(names(pR),"1",sep="")
pG        <- dataAndFitsFigureThree$FitexptAFig3G$par[2:length(dataAndFitsFigureThree$FitexptAFig3G$par)]
names(pG) <- paste(names(pG),"2",sep="")
#total parameter set to fit figure 4 is then pR+pG plus the competition parameters
p4        <- c(pR,pG,c1=1,c2=1)
```
Next construct initial conditions for N1 and N2 from the optical density data representing N1+N2

```{r}
# Determine the initial conditions from the data: optical density at start
# Assyne initially strains have equal frequency assigning half of OD to each.
fig4Data  <- readr::read_csv("Fig4/2015-11-18_RG.csv")
data4Fit  <- dplyr::bind_cols(fig4Data$Time, fig4Data$OD) %>% dplyr::rename(time = ...1, OD = ...2) %>% as.data.frame()
initialOD <- data4Fit[1,2]
s4        <- c(N1=initialOD/2,N2=initialOD/2);s4
```


```{r}
# Q4B Define which parameters are free to be fitted to the data of Fig4

# Q4B answer: Note that this should be only the competition parameters
free4     <- c("c1","c2")
```


```{r}
#Q4C Write code to do the actual fitting

#Q4C answer:
#to do the fitting
fit4      <- fit(data4Fit, odes=model2, tweak="nsol$OD=nsol$N1+nsol$N2;nsol$N1=nsol$N1/nsol$OD;nsol$N2=nsol$N2/nsol$OD",
                 free=free4, parms = p4, state = s4,
             fun=log, lower=0, upper = 2, pch=".", legend=TRUE, tstep=0.1,
             main="Fig 4 fit using monoculture param estimates from fig3 R and G for expt A\n (fraction of total OD per strain)",
             ymin = 0, ymax = 1, timeplot = TRUE, ylab = "Fraction of total OD (Density)")
#note the differences in line colors compared to the paper, unfortunately it is not easy to fix this.
#note that we use the tweak: OD=N1+N2 to plot as extra the total density from N1 and N2 summed, and also set N1 and N2 to be parts of the total population summing up to one. This makes it more similar to figure 5. If you don't do that, the plot looks like this:

fit4NotFreq      <- fit(data4Fit, odes=model2, tweak="nsol$OD=nsol$N1+nsol$N2",
                 free=free4, parms = p4, state = s4,
             fun=log, lower=0, upper = 2, pch=".", legend=TRUE, tstep=0.1,
             main="Fig 4 fit using monoculture param estimates from fig3 R and G for expt A\n (OD per strain)",
             ymin = 0, ymax = 1, timeplot = TRUE, ylab = "OD (Density)")

#to obtain parameter values and fit statistics
summary(fit4)

#in the curves you see N1 going up and N2 going down while in the fitting stats you see c1~0.6 and c2~2
#this makes perfect sense: competition with your own species has no parameter, so it is scaled at 1
#c2>1 means that N1 experiences more competition from N2 than from itself, so on its own it grows well, 
#whereas c1<1 means that N2 experience more competition from itself than N1, so on its own it grows less well.
#this causes N1 to outcompete N2

#Results are quite shaky: the standard deviation for c2 is huge, and c1 and c2 are strongly anti-correlated #(meaning that if for one you obtain a higher than for the other you obtain a lower value) suggesting they
#are strongly coupled.
#This problem can be understood from the following: competition only becomes relevant once population levels get 
#larger, and once strain1 has reached a sufficient level strain2 numbers have dropped already significantly 
#making it hard to estimate c2. 
```


```{r}
#Q4D redo the fitting for a 2D model with a single c parameter

#Q4D answer:
modelOneC <- function(t, state, parms) {
  with(as.list(c(state,parms)), {
    a1 <- q01/(q01+exp(-m1*t)); a2 <- q02/(q02+exp(-m2*t))
    dN1 <- r1*a1*N1*(1-(N1/K1)^v1-c*(N2^v2)/(K1^v1))
    dN2 <- r2*a2*N2*(1-(N2/K2)^v2-c*(N1^v1)/(K2^v2))
    return(list(c(dN1,dN2)))  
  }) 
}

p4OneC    <- c(pR,pG,c = 1)
initialOD <- data4Fit[1,2]
s4        <- c(N1=initialOD/2,N2=initialOD/2);s4  # assume the expt was started equally
free4OneC <- c("c")
fit4OneC  <- fit(data4Fit, odes=modelOneC, tweak="nsol$OD=nsol$N1+nsol$N2",free=free4OneC, parms = p4OneC, state = s4,
             fun=log, lower=0, upper = 2, pch=".", legend=TRUE, tstep=0.1,
             main="Fig 4 fit using monoculture param estimates from fig3 R and G for expt A",
             ymin = 0, ymax = 1)

summary(fit4OneC)

#The fitted curves look very similar, and also the SSR is very similar (both ~4.22).
#Interestingly the single fitted c value is very similar to the previously fitted c1 value
#rather than in between the previous c1 and c2 value, supporting the idea that the c2
#with its large standard deviation could not be trusted.
```

